{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cirrus Demo\n",
    "\n",
    "## Simple Example\n",
    "\n",
    "This will run a simple logistic regression on the Criteo Kaggle dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.12 (default, Dec  4 2017, 14:50:18) \n",
      "[GCC 5.4.0 20160609]\n"
     ]
    }
   ],
   "source": [
    "import cirrus\n",
    "from plotly import __version__\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "from plotly import tools\n",
    "import plotly.tools as tls   \n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import sys\n",
    "print(sys.version)\n",
    "\n",
    "from __future__ import print_function\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import Image, display, clear_output\n",
    "from plotly.tools import FigureFactory as FF\n",
    "from plotly.widgets import GraphWidget\n",
    "import ipywidgets as widgets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import threading\n",
    "import random\n",
    "\n",
    "class mock():\n",
    "    \n",
    "    def __init__(self, strid):\n",
    "        self.pipe = py.Stream(strid)\n",
    "        self.pipe.open()\n",
    "        self.kill_sig = threading.Event()\n",
    "    \n",
    "    def start_thread(self):\n",
    "        \n",
    "        def num_producer():\n",
    "            start_time = time.time()\n",
    "            \n",
    "            while not self.kill_sig.is_set():\n",
    "                time.sleep(0.5)\n",
    "                now_time = time.time()\n",
    "                integer = random.random()\n",
    "                self.pipe.write(dict(x = now_time - start_time, y = integer))\n",
    "        \n",
    "        self.thr = threading.Thread(target=num_producer)\n",
    "        self.thr.start()\n",
    "        \n",
    "    def kill(self):\n",
    "        print(\"Mock received kill command\")\n",
    "        self.kill_sig.set()\n",
    "        self.thr.join()\n",
    "        self.pipe.close()\n",
    "        print(\"Mock is dead\")\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Logistic Regression workload\n",
      "Starting LogisticRegressionTask\n",
      "Running Logistic Regression workload\n",
      "Starting LogisticRegressionTask\n"
     ]
    }
   ],
   "source": [
    "import cirrus\n",
    "\n",
    "\n",
    "\n",
    "data_bucket = 'cirrus-criteo-kaggle-19b-random'\n",
    "model = 'model_v1'\n",
    "\n",
    "lr_task = cirrus.LogisticRegression(\n",
    "             # number of workers\n",
    "             n_workers = 5,\n",
    "             # number of parameter servers\n",
    "             n_ps = 2,\n",
    "             # worker size in MB\n",
    "             worker_size = 128,\n",
    "             # path to s3 bucket with input dataset\n",
    "             dataset = data_bucket,\n",
    "             # sgd update LR and epsilon\n",
    "             learning_rate=0.01,\n",
    "             epsilon=0.0001,\n",
    "             progress_callback = print,\n",
    "             # stop workload after these many seconds\n",
    "             timeout = 0,\n",
    "             # stop workload once we reach this loss\n",
    "             threshold_loss=0,\n",
    "             # resume execution from model stored in this s3 bucket\n",
    "             resume_model = model,\n",
    "             # aws key name\n",
    "             key_name='mykey',\n",
    "             # path to aws key\n",
    "             key_path='/home/camus/Downloads/mykey.pem',\n",
    "             # ip where ps lives\n",
    "             ps_ip_public='ec2-54-188-0-164.us-west-2.compute.amazonaws.com',\n",
    "             ps_ip_private='172.31.26.54',\n",
    "             # username of VM\n",
    "             ps_username='ubuntu',\n",
    "             # choose between adagrad, sgd, nesterov, momentum\n",
    "             opt_method = 'adagrad',\n",
    "             # checkpoint model every x secs\n",
    "             checkpoint_model = 60,\n",
    "             #\n",
    "             minibatch_size=20,\n",
    "             # model size\n",
    "             model_bits=19,\n",
    "             # whether to filter gradient weights\n",
    "             use_grad_threshold=False,\n",
    "             # threshold value\n",
    "             grad_threshold=0.001,\n",
    "             # range of training minibatches\n",
    "             train_set=(0,824),\n",
    "             # range of testing minibatches\n",
    "             test_set=(835,840)\n",
    "             )\n",
    "\n",
    "lr_task1 = cirrus.LogisticRegression(\n",
    "             # number of workers\n",
    "             n_workers = 5,\n",
    "             # number of parameter servers\n",
    "             n_ps = 2,\n",
    "             # worker size in MB\n",
    "             worker_size = 128,\n",
    "             # path to s3 bucket with input dataset\n",
    "             dataset = data_bucket,\n",
    "             # sgd update LR and epsilon\n",
    "             learning_rate=0.01,\n",
    "             epsilon=0.0001,\n",
    "             progress_callback = print,\n",
    "             # stop workload after these many seconds\n",
    "             timeout = 0,\n",
    "             # stop workload once we reach this loss\n",
    "             threshold_loss=0,\n",
    "             # resume execution from model stored in this s3 bucket\n",
    "             resume_model = model,\n",
    "             # aws key name\n",
    "             key_name='mykey',\n",
    "             # path to aws key\n",
    "             key_path='/home/camus/Downloads/mykey.pem',\n",
    "             # ip where ps lives\n",
    "             ps_ip_public='ec2-54-188-0-164.us-west-2.compute.amazonaws.com',\n",
    "             ps_ip_private='172.31.26.54',\n",
    "             # username of VM\n",
    "             ps_username='ubuntu',\n",
    "             # choose between adagrad, sgd, nesterov, momentum\n",
    "             opt_method = 'adagrad',\n",
    "             # checkpoint model every x secs\n",
    "             checkpoint_model = 60,\n",
    "             #\n",
    "             minibatch_size=20,\n",
    "             # model size\n",
    "             model_bits=19,\n",
    "             # whether to filter gradient weights\n",
    "             use_grad_threshold=False,\n",
    "             # threshold value\n",
    "             grad_threshold=0.001,\n",
    "             # range of training minibatches\n",
    "             train_set=(0,824),\n",
    "             # range of testing minibatches\n",
    "             test_set=(835,840)\n",
    "             )\n",
    "\n",
    "\n",
    "#model, loss = lr_task.wait()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://plot.ly/~andrewmzhang/16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64181582b3a3452c9c9b3a07a3c0d9b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GraphWidget()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PS has 7 lambdas\n",
      "[{'y': 0.507192, 'x': 12.184, 'pointNumber': 3, 'curveNumber': 0}]\n",
      "Error task has received kill signal\n",
      "Lambda launcher has received kill signal\n",
      "PS has 7 lambdas\n"
     ]
    }
   ],
   "source": [
    "stream_ids = tls.get_credentials_file()['stream_ids']\n",
    "\n",
    "# Get stream id from stream id list \n",
    "stream_id0 = stream_ids[0]\n",
    "stream_id1 = stream_ids[1]\n",
    "stream_id2 = stream_ids[2]\n",
    "stream_id3 = stream_ids[3]\n",
    "\n",
    "\n",
    "stream_0 = go.Stream(\n",
    "    token=stream_id0,\n",
    "    maxpoints=80\n",
    ")\n",
    "\n",
    "stream_1 = go.Stream(\n",
    "    token=stream_id1,\n",
    "    maxpoints=80\n",
    ")\n",
    "\n",
    "stream_2 = go.Stream(\n",
    "    token=stream_id2,\n",
    "    maxpoints=80\n",
    ")\n",
    "\n",
    "stream_3 = go.Stream(\n",
    "    token=stream_id3,\n",
    "    maxpoints=80\n",
    ")\n",
    "\n",
    "trace0 = go.Scatter(\n",
    "    x=[],\n",
    "    y=[],\n",
    "    mode='lines+markers',\n",
    "    stream=stream_0         # (!) embed stream id, 1 per trace\n",
    ")\n",
    "\n",
    "trace1 = go.Scatter(\n",
    "    x=[],\n",
    "    y=[],\n",
    "    xaxis='x2',\n",
    "    yaxis='y2',\n",
    "    stream=stream_1\n",
    ")\n",
    "trace2 = go.Scatter(\n",
    "    x=[],\n",
    "    y=[],\n",
    "    xaxis='x3',\n",
    "    yaxis='y3',\n",
    "    stream=stream_2\n",
    ")\n",
    "trace3 = go.Scatter(\n",
    "    x=[],\n",
    "    y=[],\n",
    "    xaxis='x4',\n",
    "    yaxis='y4',\n",
    "    stream=stream_3\n",
    ")\n",
    "data = [trace0, trace1, trace2, trace3]\n",
    "\n",
    "layout = go.Layout(\n",
    "    xaxis=dict(\n",
    "        domain=[0, 0.45]\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        domain=[0, 0.45]\n",
    "    ),\n",
    "    xaxis2=dict(\n",
    "        domain=[0.55, 1]\n",
    "    ),\n",
    "    xaxis3=dict(\n",
    "        domain=[0, 0.45],\n",
    "        anchor='y3'\n",
    "    ),\n",
    "    xaxis4=dict(\n",
    "        domain=[0.55, 1],\n",
    "        anchor='y4'\n",
    "    ),\n",
    "    yaxis2=dict(\n",
    "        domain=[0, 0.45],\n",
    "        anchor='x2'\n",
    "    ),\n",
    "    yaxis3=dict(\n",
    "        domain=[0.55, 1]\n",
    "    ),\n",
    "    yaxis4=dict(\n",
    "        domain=[0.55, 1],\n",
    "        anchor='x4'\n",
    "    )\n",
    ")\n",
    "\n",
    "    \n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "url = py.plot(fig, filename='multiple-subplots', auto_open=False)\n",
    "print(url)\n",
    "g = GraphWidget(url)\n",
    "display(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def message_handler(widget, msg):\n",
    "    print(msg)\n",
    "    global lr_task\n",
    "    if msg[0]['curveNumber'] == 0:\n",
    "        lr_task.kill()\n",
    "\n",
    "pipe0 = py.Stream(stream_id0)\n",
    "pipe0.open()\n",
    "\n",
    "pipe1 = py.Stream(stream_id1)\n",
    "pipe1.open()\n",
    "\n",
    "def progress_callback0(time_loss, cost, task):\n",
    "    global pipe0\n",
    "    print(\"Current training loss:\", time_loss, \"current cost ($): \", cost)\n",
    "    pipe0.write(dict(x=time_loss[0], y=time_loss[1]))\n",
    "    \n",
    "def progress_callback1(time_loss, cost, task):\n",
    "    global pipe1\n",
    "    print(\"Current training loss:\", time_loss, \"current cost ($): \", cost)\n",
    "    pipe1.write(dict(x=time_loss[0], y=time_loss[1]))\n",
    "\n",
    "\n",
    "lr_task.progress_callback = progress_callback0\n",
    "lr_task1.progress_callback = progress_callback1\n",
    "\n",
    "\n",
    "g.on_click(message_handler)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13ec543a0daf41f8a312b901468a3367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description=u'Halt!', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "button = widgets.Button(description=\"Halt!\")\n",
    "display(button)\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    lr_task.kill()\n",
    "    lr_task1.kill()\n",
    "\n",
    "\n",
    "button.on_click(on_button_clicked)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User's specific ip: ec2-54-188-0-164.us-west-2.compute.amazonaws.com\n",
      "Copying ps to vm..\n",
      "Done waiting... Attempting to copy over binary\n",
      "Copied PS binary to VM\n",
      "Defining configuration file\n",
      "\n",
      "input_path: /mnt/efs/criteo_kaggle/train.csv \n",
      "input_type: csv\n",
      "num_classes: 2 \n",
      "num_features: 13 \n",
      "limit_cols: 14 \n",
      "normalize: 1 \n",
      "limit_samples: 50000000 \n",
      "s3_size: 50000 \n",
      "use_bias: 1 \n",
      "model_type: LogisticRegression \n",
      "minibatch_size: 20 \n",
      "learning_rate: 0.010000 \n",
      "epsilon: 0.000100 \n",
      "model_bits: 19 \n",
      "s3_bucket: cirrus-criteo-kaggle-19b-random \n",
      "use_grad_threshold: 0 \n",
      "grad_threshold: 0.001000 \n",
      "train_set: 0-824 \n",
      "test_set: 835-840\n",
      "\n",
      "Launching ps\n",
      "Launching parameter server\n",
      "('cmd:', 'ssh -o \"StrictHostKeyChecking no\" -i /home/camus/Downloads/mykey.pem ubuntu@ec2-54-188-0-164.us-west-2.compute.amazonaws.com \"nohup ./parameter_server --config config_lr.txt --nworkers 10000 --rank 1 &> ps_output &\"')\n",
      "Launching lambdas\n",
      "Starting error taskLambdas have been launched\n",
      "User's specific ip:\n",
      " ec2-54-188-0-164.us-west-2.compute.amazonaws.com\n",
      "Copying ps to vm..\n",
      "('cmd', 'ssh -o \"StrictHostKeyChecking no\" -i /home/camus/Downloads/mykey.pem ubuntu@ec2-54-188-0-164.us-west-2.compute.amazonaws.com \"./parameter_server --config config_lr.txt --nworkers 10 --rank 2 --ps_ip \"172.31.26.54\"\" > error_out &')\n",
      "Cost Model\n",
      "Done waiting... Attempting to copy over binary\n",
      "Copied PS binary to VM\n",
      "Defining configuration file\n",
      "\n",
      "input_path: /mnt/efs/criteo_kaggle/train.csv \n",
      "input_type: csv\n",
      "num_classes: 2 \n",
      "num_features: 13 \n",
      "limit_cols: 14 \n",
      "normalize: 1 \n",
      "limit_samples: 50000000 \n",
      "s3_size: 50000 \n",
      "use_bias: 1 \n",
      "model_type: LogisticRegression \n",
      "minibatch_size: 20 \n",
      "learning_rate: 0.010000 \n",
      "epsilon: 0.000100 \n",
      "model_bits: 19 \n",
      "s3_bucket: cirrus-criteo-kaggle-19b-random \n",
      "use_grad_threshold: 0 \n",
      "grad_threshold: 0.001000 \n",
      "train_set: 0-824 \n",
      "test_set: 835-840\n",
      "\n",
      "Launching ps\n",
      "Launching parameter server\n",
      "('cmd:', 'ssh -o \"StrictHostKeyChecking no\" -i /home/camus/Downloads/mykey.pem ubuntu@ec2-54-188-0-164.us-west-2.compute.amazonaws.com \"nohup ./parameter_server --config config_lr.txt --nworkers 10000 --rank 1 &> ps_output &\"')\n",
      "PS has 0 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.26.54\"}\n",
      "Launching lambdas\n",
      "Starting error taskLambdas have been launched\n",
      "\n",
      "('cmd', 'ssh -o \"StrictHostKeyChecking no\" -i /home/camus/Downloads/mykey.pem ubuntu@ec2-54-188-0-164.us-west-2.compute.amazonaws.com \"./parameter_server --config config_lr.txt --nworkers 10 --rank 2 --ps_ip \"172.31.26.54\"\" > error_out &')\n",
      "Cost Model\n",
      "PS has 0 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.26.54\"}\n",
      "PS has 0 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.26.54\"}\n",
      "PS has 0 lambdas\n",
      "payload: {\"num_task\": 3, \"num_workers\": 5, \"ps_ip\": \"172.31.26.54\"}\n",
      "Current training loss: (2.7081, 0.556837) current cost ($):  0.000638108957672\n",
      "PS has 7 lambdas\n",
      "Current training loss: (2.7081, 0.556837) current cost ($):  0.000382729189046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-162:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python2.7/threading.py\", line 754, in run\n",
      "    self.__target(*self.__args, **self.__kwargs)\n",
      "  File \"cirrus.py\", line 257, in error_task\n",
      "    \"task1\")\n",
      "  File \"<ipython-input-31-3b581474936a>\", line 18, in progress_callback1\n",
      "    pipe1.write(dict(x=time_loss[0], y=time_loss[1]))\n",
      "NameError: global name 'pipe1' is not defined\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PS has 7 lambdas\n",
      "PS has 7 lambdas\n",
      "Current training loss: (6.0976, 0.524193) current cost ($):  0.00089390518144\n",
      "PS has 7 lambdas\n",
      "PS has 7 lambdas\n",
      "Current training loss: (8.9093, 0.511755) current cost ($):  0.00102175602862\n",
      "PS has 7 lambdas\n",
      "PS has 7 lambdas\n",
      "PS has 7 lambdas\n",
      "Current training loss: (12.184, 0.507192) current cost ($):  0.00127733976256\n",
      "PS has 7 lambdas\n",
      "Current training loss: (14.381, 0.503572) current cost ($):  0.00140502688135\n",
      "PS has 7 lambdas\n",
      "PS has 7 lambdas\n",
      "Current training loss: (17.556, 0.502106) current cost ($):  0.0015327052021\n",
      "PS has 7 lambdas\n",
      "PS has 7 lambdas\n",
      "Current training loss: (19.851, 0.50048) current cost ($):  0.00178809595687\n",
      "PS has 7 lambdas\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "\n",
    "try:\n",
    "    lr_task.run()\n",
    "    lr_task1.run()\n",
    "except KeyboardInterrupt:\n",
    "    lr_task.kill()\n",
    "    lr_task1.kill()\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mock received kill command\n",
      "Mock is dead\n"
     ]
    }
   ],
   "source": [
    "mock_obj.kill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
